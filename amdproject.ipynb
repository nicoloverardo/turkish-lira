{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"scalable-image-classif-with-tensorflow-acc-98.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZpJoeZ-QtdQP","colab_type":"text"},"source":["# Scalable image classification with Tensorflow"]},{"cell_type":"markdown","metadata":{"id":"3omv4d2ptdQR","colab_type":"text"},"source":["Image classification via CNN - Turkish lira\n","\n","This work is the project for the Algorithms of Massive Datasets exam of the Data Science master's degree (Universit√† degli Studi di Milano, Italy)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rpNqKW3durqB","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"outputId":"b4cdbd6d-a8ce-4ccb-b153-ab758cfc35ad"},"source":["from google.colab import files\n","\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-d9fcb7ea-8f44-45da-a8ee-0a680c3f2f8e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d9fcb7ea-8f44-45da-a8ee-0a680c3f2f8e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving kaggle.json to kaggle.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QpJapncMtlcC","colab":{}},"source":["!mkdir ~/.kaggle/\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KvZVTrzru10j","colab":{}},"source":["from kaggle.api.kaggle_api_extended import KaggleApi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hQvf-xiNu4k8","colab":{}},"source":["api = KaggleApi()\n","api.authenticate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","execution":{"iopub.execute_input":"2020-07-30T12:03:45.197053Z","iopub.status.busy":"2020-07-30T12:03:45.196365Z","iopub.status.idle":"2020-07-30T12:10:09.608609Z","shell.execute_reply":"2020-07-30T12:10:09.607641Z","shell.execute_reply.started":"2020-07-30T12:03:45.196968Z"},"id":"PGK4eCvjFfL1","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"8e40f41b-a2f7-44b8-e9c0-918e61bb40e1"},"source":["api.dataset_download_files(dataset='baltacifatih/turkish-lira-banknote-dataset', path='data/', quiet=False, unzip=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 5.00M/3.50G [00:00<01:53, 33.0MB/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading turkish-lira-banknote-dataset.zip to data\n"],"name":"stdout"},{"output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.50G/3.50G [01:04<00:00, 58.2MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_jvU84rsTLZ-","trusted":true,"colab_type":"code","colab":{}},"source":["import os\n","import datetime\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n","from tensorflow.keras.models import Sequential"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2020-07-30T12:03:45.197053Z","iopub.status.busy":"2020-07-30T12:03:45.196365Z","iopub.status.idle":"2020-07-30T12:10:09.608609Z","shell.execute_reply":"2020-07-30T12:10:09.607641Z","shell.execute_reply.started":"2020-07-30T12:03:45.196968Z"},"id":"haaqzW0KtdQm","trusted":true,"colab_type":"code","colab":{}},"source":["DATASET_PATH = \"data\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66LbGJCEvV47","colab_type":"text"},"source":["In order to achieve distributed training, you should configure the `TF_CONFIG` file like\n","\n","```json\n","os.environ['TF_CONFIG'] = json.dumps({\n","    'cluster': {\n","        'worker': [\"localhost:20000\", \"localhost:20001\"]\n","    },\n","    'task': {'type': 'worker', 'index': 0}\n","})\n","```\n","\n","and replace \"localhost:20000\" and \"localhost:20001\" with the ip addresses of your workers. More info [here](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras)."]},{"cell_type":"markdown","metadata":{"id":"6RX-8kuJFYKm","colab_type":"text"},"source":["Let's define the strategy. `MultiWorkerMirroredStrategy` allows for syncronized training across multiple machines with multiple GPUs. See [here](https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy) and [here](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras) for more details."]},{"cell_type":"code","metadata":{"id":"ITjBZo5KiM5f","trusted":true,"colab_type":"code","colab":{}},"source":["strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HxDt2a5LFYKt","colab_type":"text"},"source":["We resize each picture to 64x64. Moreover, we set a batch size of 64 images per worker. In this example we are using a single worker, and that will need to change if you specify more than one worker in the `TF_CONFIG` file."]},{"cell_type":"code","metadata":{"id":"LMbnwLDskVYQ","trusted":true,"colab_type":"code","colab":{}},"source":["IMG_WIDTH = 64\n","IMG_HEIGHT = 64\n","\n","NUM_WORKERS = 1\n","PER_WORKER_BATCH_SIZE = 64\n","GLOBAL_BATCH_SIZE = PER_WORKER_BATCH_SIZE * NUM_WORKERS"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1qtITWo3FYKy","colab_type":"text"},"source":["The scalability of the input comes from the fact that we won't load all images into main memory but we'll exploit the `tf.Data` API in order to read batches of them. In order to do this, we won't use the train/test split provided in the txts but we will randomly split the data into a 80%-20% split."]},{"cell_type":"code","metadata":{"id":"uRLO05FKkTAz","trusted":true,"colab_type":"code","colab":{},"outputId":"f01d5dc6-d260-4217-9295-02950dab10f8"},"source":["train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  DATASET_PATH,\n","  validation_split=0.2,\n","  subset=\"training\",\n","  seed=123,\n","  image_size=(IMG_WIDTH, IMG_HEIGHT),\n","  label_mode='categorical',\n","  batch_size=GLOBAL_BATCH_SIZE)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 6000 files belonging to 6 classes.\n","Using 4800 files for training.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YO4yCDmYWelE","trusted":true,"colab_type":"code","colab":{},"outputId":"51719efd-42e9-4fa0-df2a-7d7171d17251"},"source":["test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n","  DATASET_PATH,\n","  validation_split=0.2,\n","  subset=\"validation\",\n","  seed=123,\n","  image_size=(IMG_WIDTH, IMG_HEIGHT),\n","  label_mode='categorical',\n","  batch_size=GLOBAL_BATCH_SIZE)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 6000 files belonging to 6 classes.\n","Using 1200 files for validation.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hb4ULOpUWtvC","trusted":true,"colab_type":"code","colab":{},"outputId":"c977b9ff-3ea6-496f-c24e-1af29579ddf5"},"source":["class_names = train_ds.class_names\n","print(class_names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['10', '100', '20', '200', '5', '50']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kp0zchcDXYTo","trusted":true,"colab_type":"code","colab":{}},"source":["num_classes = len(class_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QAbAVtCtFYLG","colab_type":"text"},"source":["We will need to scale the rgb values in order to have them in the range [0,1] which is more convenient for a neural network. This scaling will be done real-time while batch reading the images from disk."]},{"cell_type":"code","metadata":{"id":"6xyc6tN8hUAG","trusted":true,"colab_type":"code","colab":{}},"source":["def scale(image, label):\n","    image = tf.cast(image, tf.float32)\n","    image /= 255\n","\n","    return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SKzPzOfdFYLM","colab_type":"text"},"source":["We implement prefetch and caching of portions of the dataset in order to improve performance as suggested [here](https://www.tensorflow.org/guide/data_performance)"]},{"cell_type":"code","metadata":{"id":"JCKyMflZW4PB","trusted":true,"colab_type":"code","colab":{}},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_ds = train_ds.map(scale, num_parallel_calls=AUTOTUNE).repeat().cache().prefetch(buffer_size=AUTOTUNE)\n","test_ds = test_ds.map(scale, num_parallel_calls=AUTOTUNE).cache().prefetch(buffer_size=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcuqJQMYFYLQ","colab_type":"text"},"source":["We now distribute the input across multiple devices. See [here](https://www.tensorflow.org/tutorials/distribute/input) for more details."]},{"cell_type":"code","metadata":{"id":"HY3PCVN6ioKa","trusted":true,"colab_type":"code","colab":{}},"source":["dist_dataset = strategy.experimental_distribute_dataset(train_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pXLbXWp8Fl19","colab_type":"text"},"source":["Tensorboard"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XCdp0RFnFoa3","colab":{}},"source":["%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p3eTrTW6FobH","colab":{}},"source":["%tensorboard --logdir logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGfVoiUYFrok","colab_type":"code","colab":{}},"source":["logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1vubfcfsFYLU","colab_type":"text"},"source":["Let's define the model. We build the architecture of our CNN using the famous VGG blocks"]},{"cell_type":"code","metadata":{"id":"OaPGpSaNiOkS","trusted":true,"colab_type":"code","colab":{}},"source":["with strategy.scope():\n","    model = Sequential()\n","\n","    # VGG Blocks\n","    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_WIDTH,IMG_HEIGHT,3)))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(32, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Conv2D(64, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(64, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Conv2D(128, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(128, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Flatten())\n","\n","    # Dense layers\n","    model.add(Dense(128))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes, activation='softmax'))\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(), \n","                  loss=tf.keras.losses.CategoricalCrossentropy(),\n","                  metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s2JT7cipFYLZ","colab_type":"text"},"source":["Early stopping to speed up training and reduce overfitting"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2020-07-30T12:10:32.029828Z","iopub.status.busy":"2020-07-30T12:10:32.029172Z","iopub.status.idle":"2020-07-30T12:10:32.040662Z","shell.execute_reply":"2020-07-30T12:10:32.038634Z","shell.execute_reply.started":"2020-07-30T12:10:32.029745Z"},"id":"zcmO3TiQljaL","trusted":true,"colab_type":"code","colab":{}},"source":["es = EarlyStopping(monitor='loss', verbose=1, mode='min', patience = 2, min_delta=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FWlbIsDzFYLf","colab_type":"text"},"source":["Let's train the model. Since the dataset is perfectly balanced, we may skip using a validation set."]},{"cell_type":"code","metadata":{"id":"RtCckSFfljae","trusted":true,"colab_type":"code","colab":{},"outputId":"e1d232c1-462b-4ba6-943f-bdc68ac838b4"},"source":["history = model.fit(dist_dataset,\n","            epochs=15,\n","            steps_per_epoch = 75,\n","            callbacks=[es, tensorboard_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","75/75 [==============================] - 98s 1s/step - loss: 1.7677 - accuracy: 0.2048\n","Epoch 2/15\n","75/75 [==============================] - 78s 1s/step - loss: 1.3051 - accuracy: 0.4902\n","Epoch 3/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.6718 - accuracy: 0.7592\n","Epoch 4/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.4979 - accuracy: 0.8242\n","Epoch 5/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.3578 - accuracy: 0.8802\n","Epoch 6/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.2625 - accuracy: 0.9085\n","Epoch 7/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.1487 - accuracy: 0.9479\n","Epoch 8/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.1045 - accuracy: 0.9631\n","Epoch 9/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.0524 - accuracy: 0.9858\n","Epoch 10/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.1007 - accuracy: 0.9681\n","Epoch 11/15\n","75/75 [==============================] - 77s 1s/step - loss: 0.0727 - accuracy: 0.9767\n","Epoch 00011: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GR8pMkUaFYLj","colab_type":"text"},"source":["Let's evaluate it on the test set"]},{"cell_type":"code","metadata":{"id":"uou0tD1dxAzK","trusted":true,"colab_type":"code","colab":{},"outputId":"21bb1012-e1cc-495d-9e7f-90faf2c8ebef"},"source":["model.evaluate(test_ds)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["19/19 [==============================] - 15s 787ms/step - loss: 0.0652 - accuracy: 0.9800\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.06516726315021515, 0.9800000190734863]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"_65cqoEtFuvW","colab_type":"code","colab":{}},"source":["model.save(\"cnn.h5\")"],"execution_count":null,"outputs":[]}]}